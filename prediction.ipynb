{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from numerapi import NumerAPI\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, lr):\n",
    "        super(ClassificationLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.class_to_bucket = {0: 0, 1: 0.25, 2: 0.5, 3: 0.75, 4: 1}\n",
    "\n",
    "        self.history = {'loss': [], 'f1_score': []}\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, _ = self.lstm(x)\n",
    "        x = self.linear(h[:, -1, :])  # Take last output for classification\n",
    "        return x\n",
    "\n",
    "    def train_model(self, train_loader, num_epochs, device):\n",
    "        self.to(device)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0\n",
    "            all_preds, all_labels = [], []\n",
    "            for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                label_indices = torch.tensor([self.bucket_to_class(val) for val in labels.cpu().numpy()], dtype=torch.long).to(device)\n",
    "                loss = self.criterion(outputs, label_indices)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(label_indices.cpu().numpy())\n",
    "\n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, F1 Score: {f1:.4f}\")\n",
    "            self.history['loss'].append(avg_loss)\n",
    "            self.history['f1_score'].append(f1)\n",
    "\n",
    "    def bucket_to_class(self, val):\n",
    "        bucket_to_class = {v: k for k, v in self.class_to_bucket.items()}\n",
    "        return bucket_to_class[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features for prediction: ['feature_undiscoverable_tickling_volume', 'feature_haunched_cognominal_eyesore', 'feature_syndicalist_crackle_tragacanth', 'feature_organometallic_mercantile_baton', 'feature_analgesic_pensionary_exterior', 'feature_unshadowed_biometric_chokebore', 'feature_adminicular_shod_levant', 'feature_substandard_practicable_slobber', 'feature_shriveled_blightingly_laud', 'feature_catechetical_paragogical_accouterment', 'feature_vestigial_tittering_cyan', 'feature_drawn_gimcrack_vulcanalia', 'feature_haemostatic_pulpiest_pembroke', 'feature_egotistical_carotid_irrationality', 'feature_preachy_uncontaminated_servitude', 'feature_cosier_aerial_yoga', 'feature_unmovable_declassified_corrival', 'feature_upbeat_boneheaded_chequer', 'feature_simulated_shakiest_divisibility', 'feature_unfit_threatful_strontium', 'feature_xanthochroid_petrified_gutenberg', 'feature_debonnaire_opulent_stayer', 'feature_nonpersistent_miffiest_contemplator', 'feature_interlaminar_starlike_durbar', 'feature_inalterable_psilanthropic_rhotacism', 'feature_gnotobiotic_brittle_poultice', 'feature_verticillated_tenured_bosch', 'feature_choreic_sterilized_lagune', 'feature_interunion_tectricial_diaphone', 'feature_riparian_genteel_insalubrity', 'feature_rejective_carinate_ally', 'feature_whapping_liny_prelate', 'feature_chattier_tight_academic', 'feature_mullioned_hidden_niece', 'feature_muscly_splintery_stope', 'feature_appraising_chasmogamic_picrate', 'feature_homier_congestive_queening', 'feature_dorsal_phenological_hodograph', 'feature_trapped_antipapal_buffer', 'feature_calendrical_dextral_tantrum']\n"
     ]
    }
   ],
   "source": [
    "model_path = \"saved_models/model.pth\"  # Path to the saved model file\n",
    "features_file_path = \"saved_models/features.txt\"  # File containing the selected features\n",
    "live_data_path = \"data/live.parquet\"\n",
    "predictions_dir = \"predictions\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(model_path, map_location=device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with open(features_file_path, \"r\") as f:\n",
    "    selected_features = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(f\"Selected features for prediction: {selected_features}\")\n",
    "\n",
    "live_data = pd.read_parquet(live_data_path, columns=selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_df, window_len, features):\n",
    "    Xraw = data_df[features]\n",
    "    Xraw_filled = Xraw.fillna(-1)  # Replace NaN values with -1\n",
    "\n",
    "    new_data = []\n",
    "    padding = torch.full((window_len - 1, len(features)), -1)  # -1 padding for sequence\n",
    "\n",
    "    # Convert Xraw_filled to a tensor\n",
    "    Xraw_tensor = torch.tensor(Xraw_filled.values, dtype=torch.float32)\n",
    "\n",
    "    # Concatenate padding and data\n",
    "    Xraw_padded = torch.cat((padding, Xraw_tensor), dim=0)\n",
    "\n",
    "    # Sliding window approach\n",
    "    for start in range(len(Xraw_tensor)):\n",
    "        new_row_data = Xraw_padded[start : start + window_len].reshape(window_len, len(features))\n",
    "        new_data.append(new_row_data)\n",
    "\n",
    "    # Return the final tensor\n",
    "    return torch.stack(new_data)\n",
    "\n",
    "# Apply preprocessing to live data\n",
    "window_len = 5  # Window length as defined in reference code\n",
    "X_live = preprocess_data(live_data, window_len, selected_features).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions/06-11-2024_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(X_live)\n",
    "    \n",
    "    if torch.isnan(outputs).any():\n",
    "        outputs = torch.where(torch.isnan(outputs), torch.tensor(0.5, device=outputs.device), outputs)\n",
    "    \n",
    "    predictions = torch.argmax(outputs, dim=1).cpu().numpy() \n",
    "\n",
    "live_mapping = {0: 0, 1: 0.25, 2: 0.5, 3: 0.75, 4: 1}\n",
    "mapped_predictions = [live_mapping[pred] for pred in predictions]\n",
    "\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"id\": live_data.index, \n",
    "    \"prediction\": mapped_predictions\n",
    "})\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "predictions_filename = f\"{predictions_dir}/{timestamp}_predictions.csv\"\n",
    "\n",
    "predictions_df.to_csv(predictions_filename, index=False)\n",
    "print(f\"Predictions saved to {predictions_filename}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
